{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.resnet50 import ResNet50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imageSize=224\ntest_dir = ('../input/oct2017/OCT2017 /test/')\n\n# ['DME', 'CNV', 'NORMAL', '.DS_Store', 'DRUSEN']\nfrom tqdm import tqdm\ndef get_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['NORMAL']:\n                label = 0\n            elif folderName in ['CNV']:\n                label = 1\n            elif folderName in ['DME']:\n                label = 2\n            elif folderName in ['DRUSEN']:\n                label = 3\n            else:\n                label = 4\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 1))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X) # Keras only accepts data as numpy arrays \n    y = np.asarray(y)\n    return X,y\n#X_test, y_test = get_data(test_dir) # Un-comment to use full dataset: Step 1 of 2\nX_test, y_test= get_data(test_dir)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_test, y_test, test_size=0.2) # comment this ligne  to use full dataset: Step 2 of 2\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 4)\ny_testHot = to_categorical(y_test, num_classes = 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x_train, y_train = next(training_set)\n\n#valid_X,valid_Y=next(validation_set)\nxtest,ystest=next(validation_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_samples = x_train.shape[0]\nm_samplesTest = xtest.shape[0]\nX_train2 = x_train.reshape(m_samples, -1)\nX_test2 = xtest.reshape(m_samplesTest, -1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score  \n\nRandomForestClassifier=RandomForestClassifier(n_estimators=300)\n\nRandomForestClassifier.fit(X_train2,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=RandomForestClassifier.predict(X_test2)\n\nAccuracy=RandomForestClassifier.score(X_test2,ystest)\nprint('The accuracy of Random Forest classifier is : ',Accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(ystest, pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(ystest, pred, average='macro')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprecision_score(ystest, pred, average='weighted')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nrecall_score(ystest, pred, average='weighted')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.svm import SVC\nclf = svm.SVC(gamma='scale')\n#fit to the trainin data\nclf.fit(X_train2,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predSVM = classifierSVM.predict(X_test2)\nprint ('SVM  ACCURACY : ',accuracy_score(y_test, y_predSVM))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \n\nprint('SVM Precision ',precision_score(y_test, y_predSVM, average='weighted'))  \nprint('SVM Precision ',recall_score(y_test, y_predSVM, average='weighted')  )\nprint('SVM F1 score ',f1_score(y_test, y_predSVM, average='weighted') ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifierG = XGBClassifier()\nclassifierG.fit(X_train2,y_train)\n# Predicting the Test set results\ny_predXG = classifierG.predict(X_test2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('XGBOOST ACCURACY : ',accuracy_score(y_test, y_predXG))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \n\nprint('XGBOOST  Precision ',precision_score(y_test, y_predXG, average='weighted'))  \nprint('XGBOOST recall ',recall_score(y_test, y_predXG, average='weighted')  )\nprint('XGBOOST F1 score ',f1_score(y_test, y_predXG, average='weighted') ) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\nmodel = tree.DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 90000))\n# classifier.add(Dropout(p = 0.1))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n# classifier.add(Dropout(p = 0.1))\n\n# Adding the output layer\nclassifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train, y_trainHot, batch_size = 10, epochs = 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c06656ce-3c07-42f7-b1c4-2e18afcd35ed","_uuid":"5c383c7bb02cfa6a5d9959dc43d9b2c37e069999","trusted":true},"cell_type":"code","source":"classifier = Sequential()\nclassifier.add(Conv2D(32, (3, 3), input_shape = (224, 224, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (4, 4)))\nclassifier.add(Dropout(0.1))\nclassifier.add(Conv2D(512, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (3, 3)))\nclassifier.add(Conv2D(32, (3, 3), activation = 'relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(MaxPooling2D(pool_size = (3, 3)))\nclassifier.add(Flatten())\nclassifier.add(Dense(units = 128, activation = 'relu'))\nclassifier.add(Dense(units = 4, activation = 'sigmoid'))\n#classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the CNN\n\n#classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n  rescale = 1./255,\n  validation_split=0.2\n  )\ntraining_set = train_datagen.flow_from_directory('../input/oct2017/OCT2017 /train',\n  target_size = (224, 224),\n  batch_size = 80,\n  classes=[\"DME\",\"CNV\",\"NORMAL\",\"DRUSEN\"],\n  subset='training')\n \nvalidation_set = train_datagen.flow_from_directory('../input/oct2017/OCT2017 /train',\n  target_size = (224, 224),\n  batch_size = 80,\n  subset='validation',\n  classes=[\"DME\",\"CNV\",\"NORMAL\",\"DRUSEN\"])\n\ntest_set = train_datagen.flow_from_directory('../input/oct2017/OCT2017 /test',\n  target_size = (224, 224),\n  batch_size = 968,\n  classes=[\"DME\",\"CNV\",\"NORMAL\",\"DRUSEN\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = next(training_set)\n\nvalid_X,valid_Y=next(validation_set)\nxtest,ystest=next(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n \nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')\nmap_characters1 = {0: 'Normal', 1: 'CNV', 2: 'DME', 3: 'DRUSEN'}\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fcf4f7b9-80e6-404f-801a-f42bc050607e","_uuid":"2bc580bb9726dfcae4e0e1714636dc333afb17fe","trusted":true},"cell_type":"code","source":"# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n # creating checkpoint\nfrom keras.callbacks import ModelCheckpoint\nfilepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list1 = [checkpoint]\ncallbacks_list = callbacks_list1+[keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train, y_trainHot,validation_data=(X_test,y_testHot) ,batch_size = 5, epochs = 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RetinalClasses = [\"CNV\",\"DME\",\"DRUSEN\",\"NORMAL\"]\n\nPredictPathology = classifier.predict(X_test)\n\n\nfigure = plt.figure(figsize=(20, 8))\n\nfor i, index in enumerate(np.random.choice(X_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(X_test[index]))\n    predict_index = np.argmax(PredictPathology[index])\n    true_index = np.argmax(y_testHot[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(RetinalClasses[predict_index], \n                                  RetinalClasses[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"c7ff1f9e-3de7-4f81-b133-d61e91148750","_uuid":"22e1677aef70ecd984ffd2fac943ca52191aad50","trusted":true},"cell_type":"code","source":"# training model\nhistory = classifier.fit_generator(training_set, \n                                  steps_per_epoch = 66788/80,\n                                  validation_data = (valid_X,valid_Y),\n                                  validation_steps=208,\n                                  epochs = 20,\n                                  shuffle=True, \n                                  callbacks = callbacks_list+[MetricsCheckpoint('logs')])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc59fce5df7d4990330c9f2c536dd0c68ff78bd5"},"cell_type":"code","source":"labels = map_characters1\n\n# Evaluate model\nscore = classifier.evaluate(xtest,ystest, verbose=0)\nprint('\\n  CNN architecture   - accuracy ON TEST SET :', score[1], '\\n')\ny_pred = classifier.predict(xtest)\nprint('\\n', sklearn.metrics.classification_report(np.where(ystest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \nY_pred_classes = np.argmax(y_pred,axis = 1) \nY_true = np.argmax(ystest,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n#plotKerasLearningCurve()\n#plt.show()\n#plot_learning_curve(history)\n#plt.show()\nplot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6c9c5496c55fb120468c17844624fe38d4c42a","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"classifier.save('trained.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RetinalClasses = [\"CNV\",\"DME\",\"DRUSEN\",\"NORMAL\"]\n\nPredictPathology = classifier.predict(xtest)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfigure = plt.figure(figsize=(20, 8))\n\nfor i, index in enumerate(np.random.choice(xtest.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(xtest[index]))\n    predict_index = np.argmax(PredictPathology[index])\n    true_index = np.argmax(ystest[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(RetinalClasses[predict_index], \n                                  RetinalClasses[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}